{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 style=\"font-size:30px;\">1) Preparing the data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import string #to later delete punctuautions from my text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data:\n",
    "\n",
    "df1 = pd.read_csv('reviews_train.csv') #reviews\n",
    "df2 = pd.read_csv('sw.txt') #stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase:\n",
    "\n",
    "for i in range(len(df1)):\n",
    "    df1['Review'][i] = df1['Review'][i].lower()\n",
    "    df1['Label'][i] = df1['Label'][i].lower()\n",
    "    \n",
    "for j in range(len(df2)):\n",
    "    df2['about'][j] = df2['about'][j].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to numpy array\n",
    "\n",
    "df1 = df1.values\n",
    "df2 = df2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate the 'pos' and 'neg' classes:\n",
    "\n",
    "positive = 0\n",
    "negative = 0\n",
    "\n",
    "positive_reviews = np.array([])\n",
    "negative_reviews = np.array([])\n",
    "for i in range(len(df1)):\n",
    "    if df1[i, 1] == 'pos':\n",
    "        positive += 1\n",
    "        positive_reviews = np.append(positive_reviews, df1[i, 0])\n",
    "    if df1[i, 1] == 'neg':\n",
    "        negative += 1\n",
    "        negative_reviews = np.append(negative_reviews, df1[i, 0])\n",
    "\n",
    "stop_words = np.array([])\n",
    "for j in range(len(df2)):\n",
    "    stop_words = np.append(stop_words, df2[j, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminating the punctuations:\n",
    "\n",
    "for i in range(len(positive_reviews)):\n",
    "    positive_reviews[i] = positive_reviews[i].translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    \n",
    "for i in range(len(negative_reviews)):\n",
    "    negative_reviews[i] = negative_reviews[i].translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "\n",
    "#all the positive words:\n",
    "positive_words = np.array([])\n",
    "for i in range(len(positive_reviews)):\n",
    "    positive_words = np.append(positive_words, nltk.tokenize.word_tokenize(str(positive_reviews[i])))\n",
    "#     positive_words = np.append(positive_words, positive_reviews[i].split()) #but using \"nltk\" methods also seperates punctuations, etc. Hence, it is waaay better than using \".split()\"\n",
    "    \n",
    "    \n",
    "#all the negative words:    \n",
    "negative_words = np.array([])\n",
    "for i in range(len(negative_reviews)):\n",
    "    negative_words = np.append(negative_words, nltk.tokenize.word_tokenize(str(negative_reviews[i])))\n",
    "#     negative_words = np.append(negative_words, negative_reviews[i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Eliminationg words with less than a size of 1 (like 'a', '6', etc.):\n",
    "\n",
    "# positive_words_final = np.array([])\n",
    "# for j in range(len(positive_words)):\n",
    "#     if len(positive_words[j]) > 1:\n",
    "#         positive_words_final = np.append(positive_words_final, positive_words[j])\n",
    "# positive_words = positive_words_final\n",
    "\n",
    "# negative_words_final = np.array([])\n",
    "# for j in range(len(negative_words)):\n",
    "#     if len(negative_words[j]) > 1:\n",
    "#         negative_words_final = np.append(negative_words_final, negative_words[j])\n",
    "# negative_words = negative_words_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminating the stop_words:\n",
    "\n",
    "positive_words = np.array([t for t in positive_words if t not in stop_words])\n",
    "negative_words = np.array([t for t in negative_words if t not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting each word's frequency for both 'pos' and 'neg' classes:\n",
    "\n",
    "import collections\n",
    "\n",
    "positive_dic = collections.Counter(positive_words)\n",
    "negative_dic = collections.Counter(negative_words)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of elements in both 'pos' and 'neg' classes:\n",
    "\n",
    "num_positive = len(positive_words)\n",
    "num_negative = len(negative_words)\n",
    "total = num_positive + num_negative\n",
    "\n",
    "p_class_positive = positive / (positive + negative)\n",
    "p_class_negative = negative / (positive + negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #thus, in order to get p(word|class):\n",
    "# positive_dic = positive_dic / num_positive\n",
    "# negative_dic = negative_dic / num_negative\n",
    "\n",
    "# positive_dic_keys = positive_dic.keys().values()\n",
    "# positive_dic_keysfor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dic_positive = len(positive_dic)\n",
    "num_dic_negative = len(negative_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 style=\"font-size:30px;\">2,3) Classification and laplace smoothing:</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv('reviews_test.csv') #test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase:\n",
    "\n",
    "for i in range(len(df3)):\n",
    "    df3['Review'][i] = df3['Review'][i].lower()\n",
    "    df3['Label'][i] = df3['Label'][i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to numpy array\n",
    "\n",
    "df3 = df3.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "\n",
    "total_probability_positive = 1\n",
    "total_probability_negative = 1\n",
    "\n",
    "pr_positive = np.array([])\n",
    "pr_negative = np.array([])\n",
    "\n",
    "\n",
    "for i in range(len(df3)):\n",
    "    \n",
    "    review = df3[i, 0]\n",
    "    review = review.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = nltk.tokenize.word_tokenize(str(review))\n",
    "    words = np.array([t for t in words if t not in stop_words])\n",
    "    \n",
    "#     words_final = np.array([])\n",
    "#     for j in range(len(words)):\n",
    "#         if len(positive_words[j]) > 1:\n",
    "#             words_final = np.append(words_final, words[j])\n",
    "#     words = words_final\n",
    "    \n",
    "    d = int(np.unique(words).shape[0])\n",
    "    for word in words:\n",
    "        probability_positive = (positive_dic[str(word)] + a) / (num_dic_positive + a*d) #(num_dic_positive + a*(num_dic_positive + num_dic_negative)) \n",
    "        total_probability_positive *= probability_positive\n",
    "        probability_negative = (negative_dic[str(word)] + a) / (num_dic_negative + a*d)\n",
    "        total_probability_negative *= probability_negative\n",
    "\n",
    "    pr_positive = np.append(pr_positive, (total_probability_positive * p_class_positive))\n",
    "    pr_negative = np.append(pr_negative, (total_probability_negative * p_class_negative))\n",
    "    \n",
    "    probability_positive = 1\n",
    "    total_probability_positive = 1\n",
    "    probability_negative = 1\n",
    "    total_probability_negative = 1\n",
    "\n",
    "    \n",
    "pred_labels = np.array([])\n",
    "for i in range(len(df3)):\n",
    "    if (pr_positive[i] > pr_negative[i]):\n",
    "        pred_labels = np.append(pred_labels, np.array([1])) #positive\n",
    "    if (pr_positive[i] < pr_negative[i]):\n",
    "        pred_labels = np.append(pred_labels, np.array([0])) #negative\n",
    "        \n",
    "        \n",
    "        \n",
    "true_labels = np.array([])\n",
    "for i in range(len(df3)):\n",
    "    if df3[i][1] == 'pos':\n",
    "        true_labels = np.append(true_labels, np.array([1]))\n",
    "    if df3[i][1] == 'neg':\n",
    "        true_labels = np.append(true_labels, np.array([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.45845952e-323, 1.54267923e-268, 1.91124262e-231, 9.42769513e-079,\n",
       "       7.64474973e-100, 1.98664521e-049, 2.61964091e-073, 2.09662824e-128,\n",
       "       6.13207990e-102, 3.57038933e-067, 5.58970779e-068, 1.99494010e-159,\n",
       "       4.94595932e-053, 3.16088080e-123, 6.31930742e-150, 7.48980845e-159,\n",
       "       3.77658413e-162, 7.25690143e-047, 1.02855903e-057, 3.13835365e-107])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.89796855e-314, 2.03998437e-259, 1.24996139e-229, 1.63116311e-078,\n",
       "       1.31279489e-099, 1.43354832e-050, 1.88174380e-073, 1.51857150e-127,\n",
       "       1.85120776e-101, 1.27157810e-065, 3.86084623e-065, 1.36756365e-154,\n",
       "       5.20680552e-054, 1.60063992e-120, 1.47248757e-143, 3.72015871e-153,\n",
       "       2.78522630e-157, 1.11837448e-046, 2.45831565e-055, 1.57028027e-104])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 1.])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0.])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((pred_labels.reshape(len(pred_labels), 1), true_labels.reshape(len(true_labels), 1)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  1]\n",
      " [ 7  2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac = accuracy_score(true_labels, pred_labels)\n",
    "ac #the correct predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
